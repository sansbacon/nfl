
import sys; sys.path.append("/home/sansbacon/workspace/pydfs_lineup_optimizer")
missing = ['Joe Thomas', 'Ryan Succup']
from nfl.scrapers.scraper import FootballScraper
s = FootballScraper(cache_name='pos')
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        for p in soup.select('p > a'):
            print p
from nameparser import HumanName
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        for p in soup.select('p > a'):
            print p
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        for p in soup.select('p > a'):
            print p
from bs4 import BeautifulSoup
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        for p in soup.select('p > a'):
            print p
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        for a in soup.select('p > a'):
            if m == a.text:
                print a.text, a.parent.text
missing
missing = ['Joe Thomas', 'Ryan Succop']
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        for a in soup.select('p > a'):
            if m == a.text:
                print a.text, a.parent.text
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        names = [a.text for a in soup.select('p > a')]

        for p in soup.p:
            try:
                a = p.find('a')
                if '/players/' in a.get('href'):
                    if m == a.text:
                        print a.text, a.parent.text
                    else:
                        mguess, prob = process.extractOne(m, [a.text])
                        if prob > .85:
                            print a.text, a.parent.text
            except:
                pass
missing
for p in soup.p:
    print p
    
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    if name and name.last:
        # get football reference page for first letter of last name
        # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
        content = s.get(fbr_url.format(name.last[0]))
        soup = BeautifulSoup(content, 'lxml')
        names = [a.text for a in soup.select('p > a')]

        for p in soup.find_all('p'):
            try:
                a = p.find('a')
                if '/players/' in a.get('href'):
                    if m == a.text:
                        print a.text, a.parent.text
                    else:
                        mguess, prob = process.extractOne(m, [a.text])
                        if prob > .85:
                            print a.text, a.parent.text
            except:
                pass
missing
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = [a.text for a in soup.select('p > a')]

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    print a.parent.text
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .85:
                        print a.parent.text
        except:
            pass
get_ipython().magic(u'paste')
a.text for 
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)

    for a in soup.select('p > a'):
        names[a.text] += 1

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    if players.get(m) == 1:
                        print a.parent.text
                    else:
                        players[m].append(a.parent.text)
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .85:
                        print a.parent.text
        except:
            pass

    print players
from collections import defaultdict
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)

    for a in soup.select('p > a'):
        names[a.text] += 1

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    if players.get(m) == 1:
                        print a.parent.text
                    else:
                        players[m].append(a.parent.text)
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .85:
                        print a.parent.text
        except:
            pass

    print players
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)

    for a in soup.select('p > a'):
        names[a.text] += 1

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    if players.get(m) == 1:
                        print players.get(m), a.parent.text
                    else:
                        players[m].append(a.parent.text)
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .85:
                        print a.parent.text
        except:
            pass
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)

    for a in soup.select('p > a'):
        names[a.text] += 1

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    if players.get(m) == 1:
                        print a.parent.text
                    else:
                        print players.get(m), a.parent.text
                        players[m].append(a.parent.text)
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .85:
                        print a.parent.text
        except:
            pass
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)

    for a in soup.select('p > a'):
        names[a.text] += 1

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    if names.get(m) == 1:
                        print a.parent.text
                    else:
                        print names.get(m), a.parent.text
                        players[m].append(a.parent.text)
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .85:
                        print a.parent.text
        except:
            pass

    print players
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)

    for a in soup.select('p > a'):
        names[a.text] += 1

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    if names.get(m) == 1:
                        print a.parent.text
                    elif names.get(m) > 1:
                        print names.get(m), a.parent.text
                        players[m].append(a.parent.text)
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .85:
                        print a.parent.text
        except:
            pass

    print players
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    print(names.get('Joe Thomas'))
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for a in soup.select('p > a'):
        names[a.text] += 1

    print(names.get('Joe Thomas'))
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for a in soup.select('p > a'):
        print a
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for a in soup.select('p > a'):
        names[a.text] += 1

    for p in soup.find_all('p'):
        try:
            a = p.find('a')
            if '/players/' in a.get('href'):
                if m == a.text:
                    if names.get(m) == 1:
                        print a.parent.text
                    elif names.get(m) > 1:
                        print names.get(m), a.parent.text
                        players[m].append(a.parent.text)
                else:
                    mguess, prob = process.extractOne(m, [a.text])
                    if prob > .95:
                        print m, a.parent.text, prob
        except:
            pass
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for a in soup.select('p > a'):
        names[a.text] += 1
        print a.text, names[a.text]
missing = ['Joe Thomas']
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for a in soup.select('p > a'):
        names[a.text] += 1
        print a.text, names[a.text]
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for a in soup.select('p > a'):
        if 'Joe' in a.text:
            print a.text, names[a.text]
            names[a.text] += 1
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for a in soup.find_all('a'):
        if '/players/' in a.get('href'):
                print a.text, names[a.text]
                names[a.text] += 1
get_ipython().magic(u'paste')
fbr_url = 'http://www.pro-football-reference.com/players/{}/'
for m in missing:
    name = HumanName(m) #(p.get('full_name'))
    # get football reference page for first letter of last name
    # <p><a href="/players/M/MoorBr24.htm">Brian Moorman</a>(P) 2001-2013</p>
    content = s.get(fbr_url.format(name.last[0]))
    soup = BeautifulSoup(content, 'lxml')
    names = defaultdict(int)
    players = defaultdict(list)
    for p in soup.find_all('p'):
        a = p.find('a')
        if a and '/players/' in a.get('href', None):
            print a.text, names[a.text]
            names[a.text] += 1
get_ipython().magic(u'run update_player_positions.py')
get_ipython().magic(u'run update_player_positions.py')
get_ipython().magic(u'run update_player_positions.py')
get_ipython().magic(u'run update_player_positions.py')
get_ipython().magic(u'run update_player_positions.py')
